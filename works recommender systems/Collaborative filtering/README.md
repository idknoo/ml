## Коллаборативная фильтрация

Цель: определить какую оценку поставит пользователь с наибольшей точностью

Описание: датасет [MovieLens 1M Dataset](https://grouplens.org/datasets/movielens/1m/)  
Общее: [датасетыи информация](https://grouplens.org/datasets/movielens/)  
MovieLens 1M movie ratings. Stable benchmark dataset. 1 million ratings from 6000 users on 4000 movies. Released 2/2003.

### Сингулярное разложение (SVD)

Сингулярное разложение - это метод разложения матрицы на произведение трех более простых матриц: U, Σ и V<sup>T</sup>. В контексте рекомендательных систем, SVD может быть применено для разложения матрицы взаимодействий пользователей и элементов на более низкоранговые матрицы. Полученные низкоранговые матрицы могут быть использованы для заполнения пропущенных значений и предсказания рейтингов.

**Преимущества SVD:**
- Эффективно сжимает информацию о пользователях и элементах в меньшее количество латентных факторов.

**Недостатки SVD:**
- Могут возникнуть проблемы с разреженными матрицами, когда большинство значений отсутствует.

В контексте библиотеки Surprise, SVD используется для построения рекомендательных моделей. Например:

```
from surprise import SVD
from surprise import Dataset
from surprise.model_selection import cross_validate

# Загружаем данные
data = Dataset.load_builtin('ml-100k')

# Используем SVD для построения модели
model = SVD()
cross_validate(model, data, measures=['RMSE'], cv=5, verbose=True)
```

### K-ближайших соседей (KNN)

K-ближайших соседей - это метод, основанный на том, что пользователи или элементы, похожие на других, могут иметь схожие предпочтения. Для пользователя или элемента вычисляется близость с остальными, и затем используется определенное количество (K) наиболее близких для предсказания рейтингов или рекомендаций.

**Преимущества KNN:**
- Прост в реализации и понимании.
- Не требует обучения на этапе предварительной обработки.

**Недостатки KNN:**
- Вычислительно затратен, особенно при больших объемах данных.
- Может столкнуться с проблемой холодного старта для новых пользователей или элементов.

### Сравнение

- SVD обычно эффективнее в контексте рекомендаций для разреженных данных и позволяет извлекать латентные факторы.
- KNN прост в реализации, но может быть менее эффективным при большом объеме данных и наличии большого числа пользователей или элементов.

<hr>
<b>Вывод:</b> Таким образом, можно заметить, что в нашем случае почти на базовых моделях SVD справился намного лучше. Качество RMSE считалось на основе Cross-validation (5 фолдов) и отложенном датасете (test)
<hr>






