## Поиск выбросов и генерация новых признаков

Цель: изучить применение методов по поиску выбросов в данных, попрактиковаться в обработке экстремальных значений

Описание: нужно решить задачу классификации типа стекол.
Целевая переменная – тип стекла «Type». Остальные признаки описывают химические элементы в составе материала. 
Датасет нужно исследовать на наличие выбросов, провести EDA.

### Glass Classification Dataset

Описание датасета ['Glass Classification Dataset'](https://www.kaggle.com/datasets/uciml/glass)

Этот набор данных содержит информацию о химическом составе стекла и его типе. Ниже приведена информация о каждом атрибуте в наборе данных.

## Attribute Information

1. **RI (refractive index)**: Показатель преломления.
2. **Na (Sodium)**: Содержание натрия в стекле (весовой процент в соответствующем оксиде).
3. **Mg (Magnesium)**: Содержание магния в стекле.
4. **Al (Aluminum)**: Содержание алюминия в стекле.
5. **Si (Silicon)**: Содержание кремния в стекле.
6. **K (Potassium)**: Содержание калия в стекле.
7. **Ca (Calcium)**: Содержание кальция в стекле.
8. **Ba (Barium)**: Содержание бария в стекле.
9. **Fe (Iron)**: Содержание железа в стекле.
10. **Type of glass (тип стекла)**: Классовый атрибут, представляющий тип стекла. Значения могут быть следующими:
    - 1: Закаленное стекло для окон, обработанное с использованием плавления.
    - 2: Закаленное стекло для окон, не обработанное с использованием плавления.
    - 3: Закаленное стекло для автомобильных окон, обработанное с использованием плавления.
    - 4: Закаленное стекло для автомобильных окон, не обработанное с использованием плавления (отсутствует в данной базе данных).
    - 5: Стекло для контейнеров.
    - 6: Стекло для посуды.
    - 7: Стекло для фар.

**Id number (номер идентификации)**: Этот атрибут, который принимает значения от 1 до 214, был удален из CSV-файла и не включен в данные для анализа.




### Этапы работы:

1. Проанализировали датасет. Вывели графики. Пропущенных значений не оказалось. Выбросы нашлись.
2. Разделение выборки на обучающее и тестовое подмножества в соотношении 80% на обучение и 20% на тестирование.
3. Обучение модели дерева решений RandomForestClassifier на обучающем множестве и оценка точности предсказания на тестовом множестве.
4. Визуализировали распределения значений для каждой переменной с использованием графиков boxplot и distplot.
5. Исследовали признаки на выбросы с помощью межквартильного размаха (IQR). Удалили выбросы на основе IQR.
6. Сформулировали выводы по проделанной работе и сравнили метрики



| Тип данных               | Точность на тестовой выборке | Точность на тренировочной выборке |
|-------------------------|------------------------------|-----------------------------------|
| Исходные данные (X)      | 0.744                        | 1.0                               |
| Очищенные данные (X_cleaned) | 0.821                        | 1.0                               |


<hr>
<b>Вывод:</b> Когда вы удалили выбросы, то accuracy стал немного больше на тестовой выборке. Но! У нас получилась еще более переобученная модель, это можно заметить по accuracy=1.0 в тренировочной выборке. К тому же у нас очень мало данных, удалять выбросы здесь не самая лучшая идея, так как данных становится совсем мало, как уже было сказано. Еще большой вес играет random state. Если изменить этот параметр, то и вывод может получиться другой, например при random_satate=42 у нас тестовая начальная выборка показывает лучшие результаты, чем уже очищенная новая тестовая выборка. Так получается из-за малого количества данных и некоторой 'случайности', которая становится важнее и важнее при уменьшении выборки.

<hr>






