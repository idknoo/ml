#### Оценка точности модели, переобучение, регуляризация

Описание датасета ['athletes.csv'](https://www.kaggle.com/datasets/rio2016/olympic-games)

Цель: понять математический смысл метрик TPR, FPR. Изучить построение ROC-кривой, графика Precision-Recall
Описание: Решить задачу классификации при помощи обучения модели логистической регрессии. Качество модели оценивается путем подсчета метрик TPR, FPR и построения графиков ROC-кривой, Precision-Recall. 

Этапы работы:

1. Преобразовали данные. Посмотрели интересующие нас переменные. Сделали некоторые преобразования, чтобы изучить влияние зависимых переменных на целевую. 
2. Построили ROC-кривую с помощью функции sklearn.metrics. roc_curve.
3. Вычислили значение ROC-AUC метрики с помощью функции sklearn.metrics.roc_auc_score.
4. Реализовали подсчет метрик TPR, FPR «вручную», без использования готовых функций из библиотеки sklearn.
5. Построили ROC-кривую с помощью вычисленных метрик: объедините графики в один, чтобы сравнить встроенную функция sklearn и собственную
6. Построили график Precision-Recall, используя посчитанные метрики, сравнили графики

Вопросики: 
1. <i> Как по полученным графикам сделать вывод о качестве модели? Как оцениваете обученную модель исходя из подсчитанных метрик? </i>  
В ходе анализа датасета было выявлено, что у нас имеется небольшой дисбаланс классов. Так что стараемся оценить модель по метрикам 
   полноты и точности. recall получился больше 0.8, что говорит о том, что модель в примерно 8/10 верно интерпретирует целевой класс. f1 score тоже помогает понять, что модель была обучена в достаточной мере  
   По графикам можно оценить как модель бы себя вела в случайном угадывании и как ведет себя, когда мы ее обучили. Можем заметить значимые различия, а это хорошо
2. <i> Может ли ROC-кривая проходить ниже диагонали? </i>  
Нет, диагональ представляет случайный выбор, когда модель не имеет способности различать классы.  
ROC-кривая оценивает способность модели разделять положительные и отрицательные классы при разных значениях порога для вероятности положительного класса. Поэтому ROC-кривая всегда располагается выше диагонали, а ее цель - максимизировать площадь под кривой, чтобы показать, что модель лучше случайного угадывания.

accuracy = 0.8103  
precision = 0.8282  
recall = 0.8240  
f1_score = 0.8261  

roc_auc_score = 0.8860


<hr>
<b>Вывод:</b> Обучили модель, сделали расчеты. Метрики оказались все выше 0.80, данный результат нас более, чем устраивает. При подсчете можно менять трешхолды как захочется. Можно брать и опускаться по каждой точке от 1 к 0, но у нас более 2000 значений, так что показатели будут плохо интерпретироваться на графике, поэтому опускаемся каждые 0.1, либо же можно изменить значение. tpr fpr low case - расчеты sklearn, TPR FPR upper case - ручные.
<hr>






